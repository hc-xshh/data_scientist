import os
from pathlib import Path
from typing import Dict, List, Any
import json
import tempfile
from urllib.parse import urlparse
from langchain_core.tools import tool
from pydantic import BaseModel, Field

# å®‰è£…ä¾èµ–: pip install pandas openpyxl
try:
    import pandas as pd
except ImportError:
    print("è¯·å…ˆå®‰è£…ä¾èµ–: pip install pandas openpyxl")


# å·¥å…·å‚æ•°å®šä¹‰
class ParseDataFileParams(BaseModel):
    """è§£ææ•°æ®æ–‡ä»¶çš„å‚æ•°"""
    file_path: str = Field(description="æ•°æ®æ–‡ä»¶çš„å®Œæ•´è·¯å¾„æˆ–ä¸Šä¼ æ–‡ä»¶çš„URLï¼ˆå¦‚ http://localhost:5000/files/xxx.xlsxï¼‰")
    preview_rows: int = Field(default=10, description="é¢„è§ˆçš„è¡Œæ•°ï¼Œé»˜è®¤10è¡Œ")
    include_statistics: bool = Field(default=True, description="æ˜¯å¦åŒ…å«ç»Ÿè®¡ä¿¡æ¯ï¼Œé»˜è®¤True")
    save_to_file: bool = Field(default=False, description="æ˜¯å¦å°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶ï¼Œé»˜è®¤False")
    output_path: str = Field(default="", description="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœsave_to_fileä¸ºTrueåˆ™å¿…å¡«")


# è¾…åŠ©å‡½æ•°
def _detect_file_type(file_path: str) -> str:
    """æ£€æµ‹æ–‡ä»¶ç±»å‹"""
    suffix = Path(file_path).suffix.lower()
    if suffix in ['.xlsx', '.xls']:
        return 'excel'
    elif suffix == '.csv':
        return 'csv'
    elif suffix == '.json':
        return 'json'
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {suffix}ã€‚æ”¯æŒçš„æ ¼å¼: .xlsx, .xls, .csv, .json")


def _parse_excel(file_path: str, preview_rows: int = 10) -> Dict:
    """è§£æExcelæ–‡ä»¶"""
    print(f"å¼€å§‹è§£æExcelæ–‡ä»¶: {file_path}")
    
    # è¯»å–æ‰€æœ‰å·¥ä½œè¡¨
    excel_file = pd.ExcelFile(file_path)
    sheet_names = excel_file.sheet_names
    print(f"  å‘ç° {len(sheet_names)} ä¸ªå·¥ä½œè¡¨: {', '.join(sheet_names)}")
    
    result = {
        'file_type': 'Excel',
        'total_sheets': len(sheet_names),
        'sheets': []
    }
    
    for sheet_name in sheet_names:
        print(f"\n  å¤„ç†å·¥ä½œè¡¨: {sheet_name}")
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        
        sheet_data = {
            'sheet_name': sheet_name,
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'columns': list(df.columns),
            'column_types': {col: str(dtype) for col, dtype in df.dtypes.items()},
            'preview_data': df.head(preview_rows).to_dict('records'),
            'preview_text': df.head(preview_rows).to_string()
        }
        
        print(f"    è¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)}")
        
        result['sheets'].append(sheet_data)
    
    return result


def _parse_csv(file_path: str, preview_rows: int = 10) -> Dict:
    """è§£æCSVæ–‡ä»¶"""
    print(f"å¼€å§‹è§£æCSVæ–‡ä»¶: {file_path}")
    
    # å°è¯•è‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦
    try:
        # å…ˆè¯»å–ä¸€å°éƒ¨åˆ†æ¥æ£€æµ‹
        df = pd.read_csv(file_path, nrows=5)
        separator = ','
    except:
        # å°è¯•å…¶ä»–å¸¸è§åˆ†éš”ç¬¦
        for sep in ['\t', ';', '|']:
            try:
                df = pd.read_csv(file_path, sep=sep, nrows=5)
                separator = sep
                break
            except:
                continue
    
    # è¯»å–å®Œæ•´æ–‡ä»¶
    df = pd.read_csv(file_path, sep=separator)
    
    print(f"  åˆ†éš”ç¬¦: {repr(separator)}")
    print(f"  è¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)}")
    
    result = {
        'file_type': 'CSV',
        'separator': separator,
        'total_rows': len(df),
        'total_columns': len(df.columns),
        'columns': list(df.columns),
        'column_types': {col: str(dtype) for col, dtype in df.dtypes.items()},
        'preview_data': df.head(preview_rows).to_dict('records'),
        'preview_text': df.head(preview_rows).to_string()
    }
    
    return result


def _parse_json(file_path: str, preview_rows: int = 10) -> Dict:
    """è§£æJSONæ–‡ä»¶"""
    print(f"å¼€å§‹è§£æJSONæ–‡ä»¶: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    result = {
        'file_type': 'JSON',
        'data_type': type(data).__name__,
    }
    
    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°è¯•è½¬æ¢ä¸ºDataFrame
    if isinstance(data, list):
        if len(data) > 0 and isinstance(data[0], dict):
            # åˆ—è¡¨ä¸­åŒ…å«å­—å…¸ï¼Œç±»ä¼¼è¡¨æ ¼æ•°æ®
            df = pd.DataFrame(data)
            
            result.update({
                'structure': 'list_of_objects',
                'total_rows': len(df),
                'total_columns': len(df.columns),
                'columns': list(df.columns),
                'column_types': {col: str(dtype) for col, dtype in df.dtypes.items()},
                'preview_data': df.head(preview_rows).to_dict('records'),
                'preview_text': df.head(preview_rows).to_string()
            })
            
            print(f"  ç»“æ„: å¯¹è±¡åˆ—è¡¨")
            print(f"  è¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)}")
        else:
            # ç®€å•åˆ—è¡¨
            result.update({
                'structure': 'simple_list',
                'total_items': len(data),
                'preview_data': data[:preview_rows],
                'preview_text': json.dumps(data[:preview_rows], ensure_ascii=False, indent=2)
            })
            
            print(f"  ç»“æ„: ç®€å•åˆ—è¡¨")
            print(f"  å…ƒç´ æ•°: {len(data)}")
    
    elif isinstance(data, dict):
        # å­—å…¸ç»“æ„
        # å°è¯•æ£€æµ‹æ˜¯å¦åŒ…å«è¡¨æ ¼æ•°æ®
        has_table = False
        for key, value in data.items():
            if isinstance(value, list) and len(value) > 0 and isinstance(value[0], dict):
                has_table = True
                break
        
        if has_table:
            result['structure'] = 'nested_object_with_tables'
            result['keys'] = list(data.keys())
            result['preview_text'] = json.dumps({k: v[:preview_rows] if isinstance(v, list) else v 
                                                 for k, v in list(data.items())[:5]}, 
                                                ensure_ascii=False, indent=2)
            print(f"  ç»“æ„: åµŒå¥—å¯¹è±¡ï¼ˆåŒ…å«è¡¨æ ¼æ•°æ®ï¼‰")
        else:
            result['structure'] = 'simple_object'
            result['keys'] = list(data.keys())
            result['preview_text'] = json.dumps(data, ensure_ascii=False, indent=2)[:1000]
            print(f"  ç»“æ„: ç®€å•å¯¹è±¡")
    
    else:
        result.update({
            'structure': 'other',
            'preview_text': str(data)[:1000]
        })
    
    return result


def _calculate_statistics(result: Dict) -> Dict:
    """è®¡ç®—æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    stats = {}
    
    if result['file_type'] == 'Excel':
        stats['total_sheets'] = result['total_sheets']
        stats['sheets_info'] = []
        
        for sheet in result['sheets']:
            sheet_stats = {
                'name': sheet['sheet_name'],
                'rows': sheet['total_rows'],
                'columns': sheet['total_columns'],
                'column_names': sheet['columns']
            }
            stats['sheets_info'].append(sheet_stats)
    
    elif result['file_type'] == 'CSV':
        stats['total_rows'] = result['total_rows']
        stats['total_columns'] = result['total_columns']
        stats['column_names'] = result['columns']
    
    elif result['file_type'] == 'JSON':
        stats['data_type'] = result['data_type']
        stats['structure'] = result['structure']
        
        if 'total_rows' in result:
            stats['total_rows'] = result['total_rows']
            stats['total_columns'] = result['total_columns']
            stats['column_names'] = result['columns']
        elif 'total_items' in result:
            stats['total_items'] = result['total_items']
        elif 'keys' in result:
            stats['keys'] = result['keys']
    
    return stats


def _format_result(result: Dict, include_statistics: bool = True) -> str:
    """æ ¼å¼åŒ–è§£æç»“æœä¸ºå¯è¯»æ–‡æœ¬"""
    lines = []
    
    lines.append(f"æ–‡ä»¶ç±»å‹: {result['file_type']}")
    lines.append("")
    
    # ç»Ÿè®¡ä¿¡æ¯
    if include_statistics:
        lines.append("ã€ç»Ÿè®¡ä¿¡æ¯ã€‘")
        stats = _calculate_statistics(result)
        
        if result['file_type'] == 'Excel':
            lines.append(f"  å·¥ä½œè¡¨æ•°é‡: {stats['total_sheets']}")
            for sheet_info in stats['sheets_info']:
                lines.append(f"\n  å·¥ä½œè¡¨: {sheet_info['name']}")
                lines.append(f"    è¡Œæ•°: {sheet_info['rows']}")
                lines.append(f"    åˆ—æ•°: {sheet_info['columns']}")
                lines.append(f"    åˆ—å: {', '.join(sheet_info['column_names'])}")
        
        elif result['file_type'] == 'CSV':
            lines.append(f"  åˆ†éš”ç¬¦: {repr(result['separator'])}")
            lines.append(f"  è¡Œæ•°: {stats['total_rows']}")
            lines.append(f"  åˆ—æ•°: {stats['total_columns']}")
            lines.append(f"  åˆ—å: {', '.join(stats['column_names'])}")
        
        elif result['file_type'] == 'JSON':
            lines.append(f"  æ•°æ®ç±»å‹: {stats['data_type']}")
            lines.append(f"  ç»“æ„: {stats['structure']}")
            
            if 'total_rows' in stats:
                lines.append(f"  è¡Œæ•°: {stats['total_rows']}")
                lines.append(f"  åˆ—æ•°: {stats['total_columns']}")
                lines.append(f"  åˆ—å: {', '.join(stats['column_names'])}")
            elif 'total_items' in stats:
                lines.append(f"  å…ƒç´ æ•°: {stats['total_items']}")
            elif 'keys' in stats:
                lines.append(f"  é”®: {', '.join(stats['keys'])}")
        
        lines.append("")
    
    # æ•°æ®é¢„è§ˆ
    lines.append("ã€æ•°æ®é¢„è§ˆã€‘")
    
    if result['file_type'] == 'Excel':
        for sheet in result['sheets']:
            lines.append(f"\nå·¥ä½œè¡¨: {sheet['sheet_name']}")
            lines.append(sheet['preview_text'])
    
    elif result['file_type'] in ['CSV', 'JSON']:
        if 'preview_text' in result:
            lines.append(result['preview_text'])
    
    return '\n'.join(lines)


def _parse_data_file_complete(file_path: str, preview_rows: int = 10) -> Dict:
    """
    å®Œæ•´è§£ææ•°æ®æ–‡ä»¶ï¼ˆExcel/CSV/JSONï¼‰
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„æˆ–URL
        preview_rows: é¢„è§ˆè¡Œæ•°
    
    Returns:
        åŒ…å«å®Œæ•´æ•°æ®ä¿¡æ¯çš„å­—å…¸
    """
    # å¤„ç† URL æ ¼å¼çš„è·¯å¾„
    if file_path.startswith('http://') or file_path.startswith('https://'):
        # ä» URL ä¸­æå–æ–‡ä»¶å
        parsed_url = urlparse(file_path)
        filename = os.path.basename(parsed_url.path)
        # æ„å»ºä¸´æ—¶æ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„
        local_file_path = os.path.join(tempfile.gettempdir(), filename)
        print(f"æ£€æµ‹åˆ°URLæ ¼å¼ï¼Œè½¬æ¢ä¸ºæœ¬åœ°è·¯å¾„: {local_file_path}")
    else:
        local_file_path = file_path
    
    if not Path(local_file_path).exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {local_file_path}")
    
    # æ£€æµ‹æ–‡ä»¶ç±»å‹
    file_type = _detect_file_type(local_file_path)
    
    # æ ¹æ®ç±»å‹è§£æ
    if file_type == 'excel':
        result = _parse_excel(local_file_path, preview_rows)
    elif file_type == 'csv':
        result = _parse_csv(local_file_path, preview_rows)
    elif file_type == 'json':
        result = _parse_json(local_file_path, preview_rows)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")
    
    result['file_path'] = file_path
    result['file_name'] = Path(local_file_path).name
    result['file_size'] = Path(local_file_path).stat().st_size
    
    print(f"\n{'='*80}")
    print("æ–‡ä»¶è§£æå®Œæˆï¼")
    print(f"{'='*80}")
    
    return result


def _save_result_to_file(result: Dict, output_path: str):
    """å°†è§£æç»“æœä¿å­˜åˆ°æ–‡ä»¶"""
    content = _format_result(result, include_statistics=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_path}")


# å®šä¹‰langchainå·¥å…·

@tool(args_schema=ParseDataFileParams)
def parse_data_file(
    file_path: str,
    preview_rows: int = 10,
    include_statistics: bool = True,
    save_to_file: bool = False,
    output_path: str = ""
) -> str:
    """
    å®Œæ•´è§£ææ•°æ®æ–‡ä»¶ï¼ˆExcel/CSV/JSONï¼‰ï¼Œæå–ç»“æ„ä¿¡æ¯ã€ç»Ÿè®¡æ•°æ®å¹¶é¢„è§ˆå†…å®¹ã€‚
    
    é€‚ç”¨åœºæ™¯:
    - åˆ†æExcelè¡¨æ ¼æ•°æ®å’Œå¤šä¸ªå·¥ä½œè¡¨
    - è§£æCSVæ•°æ®æ–‡ä»¶
    - è¯»å–å’Œç†è§£JSONæ•°æ®ç»“æ„
    - è·å–æ•°æ®æ–‡ä»¶çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    - é¢„è§ˆæ•°æ®å†…å®¹å’Œåˆ—ä¿¡æ¯
    - æ£€æŸ¥æ•°æ®æ–‡ä»¶çš„æ ¼å¼å’Œç»“æ„
    - ç»Ÿè®¡æ•°æ®è¡Œæ•°ã€åˆ—æ•°ã€æ•°æ®ç±»å‹
    
    åŠŸèƒ½ç‰¹ç‚¹:
    - æ”¯æŒExcelæ–‡ä»¶ï¼ˆ.xlsx, .xlsï¼‰- è‡ªåŠ¨å¤„ç†å¤šä¸ªå·¥ä½œè¡¨
    - æ”¯æŒCSVæ–‡ä»¶ - è‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦ï¼ˆé€—å·ã€åˆ¶è¡¨ç¬¦ã€åˆ†å·ç­‰ï¼‰
    - æ”¯æŒJSONæ–‡ä»¶ - æ™ºèƒ½è¯†åˆ«ä¸åŒçš„JSONç»“æ„ï¼ˆå¯¹è±¡åˆ—è¡¨ã€åµŒå¥—å¯¹è±¡ç­‰ï¼‰
    - æå–åˆ—åå’Œæ•°æ®ç±»å‹ä¿¡æ¯
    - ç»Ÿè®¡è¡Œæ•°ã€åˆ—æ•°ç­‰åŸºæœ¬ä¿¡æ¯
    - æ•°æ®é¢„è§ˆï¼ˆå¯é…ç½®é¢„è§ˆè¡Œæ•°ï¼‰
    - å¯é€‰ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    - æ”¯æŒæœ¬åœ°è·¯å¾„å’Œä¸Šä¼ æ–‡ä»¶URLï¼ˆè‡ªåŠ¨ä»ä¸´æ—¶æ–‡ä»¶å¤¹è·å–ï¼‰
    
    å‚æ•°è¯´æ˜:
    - file_path: æ•°æ®æ–‡ä»¶çš„å®Œæ•´è·¯å¾„æˆ–ä¸Šä¼ æ–‡ä»¶çš„URLï¼ˆå¦‚ http://localhost:5000/files/xxx.xlsxï¼‰
    - preview_rows: é¢„è§ˆçš„è¡Œæ•°ï¼Œé»˜è®¤10è¡Œ
    - include_statistics: æ˜¯å¦åŒ…å«ç»Ÿè®¡ä¿¡æ¯ï¼Œé»˜è®¤True
    - save_to_file: æ˜¯å¦å°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶
    - output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå½“save_to_fileä¸ºTrueæ—¶å¿…å¡«ï¼‰
    
    æ³¨æ„äº‹é¡¹:
    - éœ€è¦å®‰è£…pandaså’Œopenpyxlåº“
    - Excelæ–‡ä»¶éœ€è¦openpyxlæ”¯æŒ
    - CSVæ–‡ä»¶ä¼šè‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦
    - JSONæ–‡ä»¶æ”¯æŒå¤šç§ç»“æ„ï¼ˆåˆ—è¡¨ã€å¯¹è±¡ã€åµŒå¥—ç»“æ„ç­‰ï¼‰
    - å¤§æ–‡ä»¶åªé¢„è§ˆæŒ‡å®šè¡Œæ•°ä»¥æé«˜æ€§èƒ½
    
    è¿”å›:
    - åŒ…å«æ•°æ®æ–‡ä»¶å®Œæ•´ä¿¡æ¯çš„æ–‡æœ¬ï¼ŒåŒ…æ‹¬ç»Ÿè®¡ä¿¡æ¯å’Œæ•°æ®é¢„è§ˆ
    """
    try:
        # è§£ææ–‡ä»¶
        result = _parse_data_file_complete(file_path, preview_rows)
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted_result = _format_result(result, include_statistics)
        
        # å¯é€‰ä¿å­˜åˆ°æ–‡ä»¶
        if save_to_file:
            if not output_path:
                output_path = str(Path(file_path).with_suffix('.txt'))
            _save_result_to_file(result, output_path)
        
        # æ„å»ºæ‘˜è¦ä¿¡æ¯
        summary_parts = [f"""æ•°æ®æ–‡ä»¶è§£æå®Œæˆï¼

ğŸ“„ æ–‡ä»¶ä¿¡æ¯:
  - æ–‡ä»¶å: {result['file_name']}
  - æ–‡ä»¶å¤§å°: {result['file_size']:,} å­—èŠ‚ ({result['file_size'] / 1024:.2f} KB)
  - æ–‡ä»¶ç±»å‹: {result['file_type']}
"""]
        
        # æ·»åŠ ç±»å‹ç‰¹å®šçš„ç»Ÿè®¡ä¿¡æ¯
        if result['file_type'] == 'Excel':
            summary_parts.append(f"  - å·¥ä½œè¡¨æ•°: {result['total_sheets']}")
            total_rows = sum(sheet['total_rows'] for sheet in result['sheets'])
            summary_parts.append(f"  - æ€»è¡Œæ•°: {total_rows}")
        elif result['file_type'] == 'CSV':
            summary_parts.append(f"  - è¡Œæ•°: {result['total_rows']}")
            summary_parts.append(f"  - åˆ—æ•°: {result['total_columns']}")
        elif result['file_type'] == 'JSON':
            summary_parts.append(f"  - æ•°æ®ç»“æ„: {result['structure']}")
            if 'total_rows' in result:
                summary_parts.append(f"  - è¡Œæ•°: {result['total_rows']}")
        
        summary_parts.append(f"""
{'='*80}
å®Œæ•´å†…å®¹:
{'='*80}

{formatted_result}
""")
        
        return '\n'.join(summary_parts)
        
    except FileNotFoundError as e:
        return f"âŒ é”™è¯¯: {str(e)}"
    except Exception as e:
        return f"âŒ æ–‡ä»¶è§£æå¤±è´¥: {str(e)}\nè¯·ç¡®ä¿æ–‡ä»¶æ ¼å¼æ­£ç¡®ä¸”å·²å®‰è£…å¿…è¦çš„ä¾èµ–ï¼ˆpip install pandas openpyxlï¼‰"


# å¯¼å‡ºå·¥å…·åˆ—è¡¨
data_parser_tools = [
    parse_data_file
]
