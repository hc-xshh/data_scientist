import os
from typing import TypedDict, Annotated, Sequence, Dict, Any, List, Optional, Literal
from pathlib import Path
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langchain_deepseek import ChatDeepSeek
from langchain_community.document_loaders import (
    TextLoader,
    PyPDFLoader,
    Docx2txtLoader,
    UnstructuredFileLoader,
    CSVLoader,
    UnstructuredExcelLoader,
    UnstructuredMarkdownLoader,
)
from langchain_core.tools import tool
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, Field
import json

# --- ç¯å¢ƒé…ç½® ---
# ç¡®ä¿è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:
# OPENAI_API_KEY æˆ– DEEPSEEK_API_KEY - ä½ çš„APIå¯†é’¥
# LANGCHAIN_API_KEY - ä½ çš„LangSmith APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
# LANGCHAIN_TRACING_V2=true - å¯ç”¨LangSmithè¿½è¸ªï¼ˆå¯é€‰ï¼‰
# LANGCHAIN_PROJECT="File Analysis Agent" - é¡¹ç›®åç§°ï¼ˆå¯é€‰ï¼‰

# å¦‚æœç¯å¢ƒä¸­æ²¡æœ‰è®¾ç½®ï¼Œå¯ä»¥åœ¨è¿™é‡Œè®¾ç½®
if os.getenv("LANGCHAIN_API_KEY"):
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_PROJECT"] = "File Analysis Agent"

# --- çŠ¶æ€å®šä¹‰ ---
class AgentState(TypedDict):
    """æ™ºèƒ½ä½“çš„çŠ¶æ€æ¨¡å¼"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    file_path: Optional[str]
    file_content: Optional[str]
    file_metadata: Optional[Dict[str, Any]]
    analysis_result: Optional[str]
    error: Optional[str]
    current_step: Optional[str]  # ç”¨äºè¿½è¸ªå½“å‰æ­¥éª¤

# --- æ”¯æŒçš„æ–‡ä»¶ç±»å‹ ---
SUPPORTED_EXTENSIONS = {
    ".txt": TextLoader,
    ".pdf": PyPDFLoader,
    ".doc": Docx2txtLoader,
    ".docx": Docx2txtLoader,
    ".csv": CSVLoader,
    ".xlsx": UnstructuredExcelLoader,
    ".xls": UnstructuredExcelLoader,
    ".md": UnstructuredMarkdownLoader,
}

# --- å·¥å…·å®šä¹‰ ---
@tool
def validate_file(file_path: str) -> Dict[str, Any]:
    """éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»"""
    try:
        path = Path(file_path)
        
        if not path.exists():
            return {
                "valid": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }
        
        if not path.is_file():
            return {
                "valid": False,
                "error": f"è·¯å¾„ä¸æ˜¯ä¸€ä¸ªæ–‡ä»¶: {file_path}"
            }
        
        ext = path.suffix.lower()
        if ext not in SUPPORTED_EXTENSIONS:
            return {
                "valid": False,
                "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {ext}ã€‚æ”¯æŒçš„ç±»å‹: {', '.join(SUPPORTED_EXTENSIONS.keys())}"
            }
        
        # è·å–æ–‡ä»¶å…ƒæ•°æ®
        stat = path.stat()
        return {
            "valid": True,
            "file_name": path.name,
            "file_type": ext,
            "file_size": stat.st_size,
            "file_size_mb": round(stat.st_size / (1024 * 1024), 2)
        }
    except Exception as e:
        return {
            "valid": False,
            "error": f"éªŒè¯æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
        }

@tool
def load_file(file_path: str) -> Dict[str, Any]:
    """åŠ è½½å¹¶è¯»å–æ–‡ä»¶å†…å®¹"""
    try:
        path = Path(file_path)
        ext = path.suffix.lower()
        
        # é€‰æ‹©åˆé€‚çš„åŠ è½½å™¨
        if ext in SUPPORTED_EXTENSIONS:
            loader_class = SUPPORTED_EXTENSIONS[ext]
            loader = loader_class(file_path)
        else:
            # å°è¯•ä½¿ç”¨é€šç”¨åŠ è½½å™¨
            loader = UnstructuredFileLoader(file_path)
        
        documents = loader.load()
        content = "\n\n".join([doc.page_content for doc in documents])
        
        # ä¸ºäº†é¿å…tokenè¿‡å¤šï¼Œé™åˆ¶å†…å®¹é•¿åº¦
        max_chars = 10000
        truncated = len(content) > max_chars
        if truncated:
            content_preview = content[:max_chars] + "\n\n... [å†…å®¹å·²æˆªæ–­ï¼Œä»…æ˜¾ç¤ºå‰10000å­—ç¬¦]"
        else:
            content_preview = content
        
        return {
            "success": True,
            "content": content_preview,
            "full_content": content,
            "truncated": truncated,
            "char_count": len(content),
            "page_count": len(documents)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

# --- èŠ‚ç‚¹å‡½æ•°å®šä¹‰ ---
def validate_input(state: AgentState, config: RunnableConfig) -> AgentState:
    """éªŒè¯ç”¨æˆ·è¾“å…¥å’Œæ–‡ä»¶"""
    print("ğŸ” æ­£åœ¨éªŒè¯æ–‡ä»¶...")
    
    if not state.get("file_path"):
        return {
            **state,
            "error": "æ²¡æœ‰æä¾›æ–‡ä»¶è·¯å¾„ï¼Œè¯·æŒ‡å®šè¦åˆ†æçš„æ–‡ä»¶",
            "current_step": "validation_failed"
        }
    
    # éªŒè¯æ–‡ä»¶
    validation_result = validate_file.invoke({"file_path": state["file_path"]})
    
    if not validation_result.get("valid"):
        return {
            **state,
            "error": validation_result.get("error"),
            "current_step": "validation_failed"
        }
    
    print(f"âœ… æ–‡ä»¶éªŒè¯æˆåŠŸ: {validation_result['file_name']} ({validation_result['file_size_mb']}MB)")
    
    return {
        **state,
        "file_metadata": validation_result,
        "current_step": "validated",
        "error": None
    }

def process_file(state: AgentState, config: RunnableConfig) -> AgentState:
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    print("ğŸ”„ æ­£åœ¨åŠ è½½æ–‡ä»¶å†…å®¹...")
    
    try:
        # ä½¿ç”¨å·¥å…·åŠ è½½æ–‡ä»¶
        file_result = load_file.invoke({"file_path": state["file_path"]})
        
        if not file_result.get("success"):
            return {
                **state,
                "error": f"æ–‡ä»¶åŠ è½½å¤±è´¥: {file_result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                "current_step": "load_failed"
            }
        
        print(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸ - å­—ç¬¦æ•°: {file_result.get('char_count')}, é¡µæ•°: {file_result.get('page_count')}")
        if file_result.get("truncated"):
            print("âš ï¸ å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ç”¨äºåˆ†æ")
        
        return {
            **state,
            "file_content": file_result["content"],
            "current_step": "loaded",
            "error": None
        }
    except Exception as e:
        return {
            **state,
            "error": f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}",
            "current_step": "load_failed"
        }

def analyze_content(state: AgentState, config: RunnableConfig) -> AgentState:
    """ä½¿ç”¨LLMåˆ†ææ–‡ä»¶å†…å®¹"""
    print("ğŸ§  æ­£åœ¨ä½¿ç”¨AIåˆ†æå†…å®¹...")
    
    if not state.get("file_content"):
        return {
            **state,
            "error": "æ²¡æœ‰æ–‡ä»¶å†…å®¹å¯ä¾›åˆ†æ",
            "current_step": "analysis_failed"
        }
    
    try:
        # åˆå§‹åŒ–LLM - ä¼˜å…ˆä½¿ç”¨DeepSeekï¼ˆæˆæœ¬æ›´ä½ï¼‰ï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨OpenAI
        if os.getenv("DEEPSEEK_API_KEY"):
            llm = ChatDeepSeek(model="deepseek-chat", temperature=0)
            print("ğŸ“¡ ä½¿ç”¨DeepSeekæ¨¡å‹...")
        elif os.getenv("OPENAI_API_KEY"):
            llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
            print("ğŸ“¡ ä½¿ç”¨OpenAIæ¨¡å‹...")
        else:
            return {
                **state,
                "error": "æœªé…ç½®LLM APIå¯†é’¥ï¼Œè¯·è®¾ç½®DEEPSEEK_API_KEYæˆ–OPENAI_API_KEYç¯å¢ƒå˜é‡",
                "current_step": "analysis_failed"
            }
        
        # è·å–æ–‡ä»¶å…ƒæ•°æ®
        file_name = state.get("file_metadata", {}).get("file_name", "æœªçŸ¥æ–‡ä»¶")
        file_type = state.get("file_metadata", {}).get("file_type", "æœªçŸ¥ç±»å‹")
        
        # åˆ›å»ºç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡ä»¶åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹ï¼Œå¹¶æä¾›å…¨é¢ã€ç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Šã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¿›è¡Œåˆ†æï¼š

1. **æ–‡ä»¶æ¦‚è§ˆ**
   - æ–‡ä»¶ç±»å‹å’Œæ ¼å¼
   - æ•´ä½“ç»“æ„å’Œç»„ç»‡æ–¹å¼

2. **å†…å®¹æ‘˜è¦**ï¼ˆ150-200å­—ï¼‰
   - ç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“æ–‡ä»¶çš„ä¸»è¦å†…å®¹

3. **å…³é”®ä¸»é¢˜å’Œè¦ç‚¹**
   - åˆ—å‡º3-5ä¸ªæœ€é‡è¦çš„ä¸»é¢˜æˆ–è¦ç‚¹
   - æ¯ä¸ªè¦ç‚¹ç”¨ç®€çŸ­çš„æ®µè½è¯´æ˜

4. **æ·±å…¥åˆ†æ**
   - å†…å®¹è´¨é‡è¯„ä¼°
   - è¯­è¨€é£æ ¼å’Œè¯­è°ƒ
   - ç›®æ ‡å—ä¼—è¯†åˆ«
   - ä»»ä½•ç‰¹æ®Šçš„æ ¼å¼æˆ–ç»“æ„

5. **å…³é”®å‘ç°**
   - é‡è¦æ•°æ®ã€äº‹å®æˆ–è®ºç‚¹
   - å€¼å¾—æ³¨æ„çš„è§è§£æˆ–è§‚ç‚¹

6. **å»ºè®®å’Œåç»­è¡ŒåŠ¨**ï¼ˆå¦‚é€‚ç”¨ï¼‰
   - å¯¹å†…å®¹çš„æ”¹è¿›å»ºè®®
   - å¯èƒ½çš„åº”ç”¨åœºæ™¯

è¯·ç”¨æ¸…æ™°ã€ä¸“ä¸šçš„ä¸­æ–‡æ’°å†™åˆ†ææŠ¥å‘Šï¼Œä½¿ç”¨Markdownæ ¼å¼ä½¿æŠ¥å‘Šæ˜“äºé˜…è¯»ã€‚"""

        # åˆ›å»ºç”¨æˆ·æç¤º
        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡ä»¶ï¼š

**æ–‡ä»¶å:** {file_name}
**æ–‡ä»¶ç±»å‹:** {file_type}

**æ–‡ä»¶å†…å®¹:**
```
{state["file_content"]}
```

è¯·æä¾›è¯¦ç»†çš„åˆ†ææŠ¥å‘Šã€‚"""
        
        # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ]
        
        print("ğŸ’­ æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        response = llm.invoke(messages, config=config)
        
        print("âœ… å†…å®¹åˆ†ææˆåŠŸ")
        return {
            **state,
            "analysis_result": response.content,
            "current_step": "analyzed",
            "error": None
        }
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"âŒ åˆ†æå‡ºé”™: {str(e)}")
        return {
            **state,
            "error": f"åˆ†æå†…å®¹æ—¶å‡ºé”™: {str(e)}",
            "current_step": "analysis_failed"
        }

def format_response(state: AgentState, config: RunnableConfig) -> AgentState:
    """æ ¼å¼åŒ–æœ€ç»ˆå“åº”ç»™ç”¨æˆ·"""
    print("ğŸ“ æ­£åœ¨æ ¼å¼åŒ–æœ€ç»ˆå“åº”...")
    
    if state.get("error"):
        response_content = f"""âŒ **å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯**

**é”™è¯¯ä¿¡æ¯:** {state['error']}

**å»ºè®®:**
- è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®è®¤æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒï¼ˆæ”¯æŒ: {', '.join(SUPPORTED_EXTENSIONS.keys())}ï¼‰
- éªŒè¯æ–‡ä»¶æ˜¯å¦å¯ä»¥æ­£å¸¸è®¿é—®
"""
    elif state.get("analysis_result"):
        file_info = state.get("file_metadata", {})
        file_name = file_info.get("file_name", "æœªçŸ¥")
        file_size = file_info.get("file_size_mb", "æœªçŸ¥")
        
        response_content = f"""âœ… **æ–‡ä»¶åˆ†æå®Œæˆ**

---

**æ–‡ä»¶ä¿¡æ¯:**
- æ–‡ä»¶å: `{file_name}`
- æ–‡ä»¶å¤§å°: {file_size}MB

---

{state['analysis_result']}

---

*åˆ†æç”±AIç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*
"""
    else:
        response_content = "âš ï¸ æœªèƒ½ç”Ÿæˆåˆ†æç»“æœï¼Œè¯·é‡è¯•"
    
    return {
        **state,
        "messages": [*state["messages"], AIMessage(content=response_content)]
    }

# --- æ¡ä»¶è·¯ç”±å‡½æ•° ---
def should_continue(state: AgentState) -> Literal["process_file", "handle_error"]:
    """å†³å®šéªŒè¯åçš„ä¸‹ä¸€æ­¥"""
    if state.get("current_step") == "validation_failed":
        return "handle_error"
    return "process_file"

def after_load(state: AgentState) -> Literal["analyze_content", "handle_error"]:
    """å†³å®šåŠ è½½åçš„ä¸‹ä¸€æ­¥"""
    if state.get("current_step") == "load_failed":
        return "handle_error"
    return "analyze_content"

def after_analysis(state: AgentState) -> Literal["format_response", "handle_error"]:
    """å†³å®šåˆ†æåçš„ä¸‹ä¸€æ­¥"""
    if state.get("current_step") == "analysis_failed":
        return "handle_error"
    return "format_response"

def handle_error(state: AgentState, config: RunnableConfig) -> AgentState:
    """å¤„ç†é”™è¯¯æƒ…å†µ"""
    print(f"âš ï¸ é”™è¯¯å¤„ç†èŠ‚ç‚¹: {state.get('error')}")
    # é”™è¯¯å·²ç»åœ¨stateä¸­ï¼Œç›´æ¥è¿”å›
    return state

# --- æ„å»ºå›¾ ---
def create_file_analysis_graph():
    """åˆ›å»ºæ–‡ä»¶åˆ†æçŠ¶æ€å›¾"""
    print("ğŸ—ï¸ æ„å»ºæ–‡ä»¶åˆ†æå·¥ä½œæµå›¾...")
    
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
    workflow.add_node("validate_input", validate_input)
    workflow.add_node("process_file", process_file)
    workflow.add_node("analyze_content", analyze_content)
    workflow.add_node("handle_error", handle_error)
    workflow.add_node("format_response", format_response)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.add_edge(START, "validate_input")
    
    # æ·»åŠ æ¡ä»¶è¾¹
    workflow.add_conditional_edges(
        "validate_input",
        should_continue,
        {
            "process_file": "process_file",
            "handle_error": "handle_error"
        }
    )
    
    workflow.add_conditional_edges(
        "process_file",
        after_load,
        {
            "analyze_content": "analyze_content",
            "handle_error": "handle_error"
        }
    )
    
    workflow.add_conditional_edges(
        "analyze_content",
        after_analysis,
        {
            "format_response": "format_response",
            "handle_error": "handle_error"
        }
    )
    
    # é”™è¯¯å¤„ç†åä¹Ÿæ ¼å¼åŒ–å“åº”
    workflow.add_edge("handle_error", "format_response")
    
    # æœ€ç»ˆèŠ‚ç‚¹
    workflow.add_edge("format_response", END)
    
    # ç¼–è¯‘å›¾ï¼ˆæ·»åŠ å†…å­˜ä»¥æ”¯æŒå¤šè½®å¯¹è¯ï¼‰
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)
    
    print("âœ… å·¥ä½œæµå›¾æ„å»ºå®Œæˆ")
    return app

# --- ä¸»åº”ç”¨ ---
def main():
    """ä¸»å‡½æ•° - ç”¨äºæœ¬åœ°æµ‹è¯•"""
    print("ğŸš€ åˆå§‹åŒ–æ–‡ä»¶åˆ†ææ™ºèƒ½ä½“...")
    print("="*60)
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    app = create_file_analysis_graph()
    
    # ç¤ºä¾‹æ–‡ä»¶è·¯å¾„ - è¯·æ›¿æ¢ä¸ºå®é™…æ–‡ä»¶è·¯å¾„
    # ä½ å¯ä»¥ä¿®æ”¹è¿™é‡Œæ¥æµ‹è¯•ä¸åŒçš„æ–‡ä»¶
    import sys
    
    if len(sys.argv) > 1:
        # ä»å‘½ä»¤è¡Œå‚æ•°è·å–æ–‡ä»¶è·¯å¾„
        sample_file_path = sys.argv[1]
    else:
        # é»˜è®¤ç¤ºä¾‹è·¯å¾„ - è¯·ä¿®æ”¹ä¸ºä½ çš„æµ‹è¯•æ–‡ä»¶
        sample_file_path = r"D:\HAHA\é¡¹ç›®\Aå…¬å¸\code\data_scientist\README.md"
    
    print(f"ğŸ“„ å‡†å¤‡åˆ†ææ–‡ä»¶: {sample_file_path}")
    print("="*60)
    
    # åˆå§‹çŠ¶æ€
    initial_state = {
        "messages": [HumanMessage(content=f"è¯·å¸®æˆ‘åˆ†æè¿™ä¸ªæ–‡ä»¶: {sample_file_path}")],
        "file_path": sample_file_path,
        "file_content": None,
        "file_metadata": None,
        "analysis_result": None,
        "error": None,
        "current_step": "initial"
    }
    
    # é…ç½®ï¼ˆç”¨äºLangSmithè¿½è¸ªå’Œä¼šè¯ç®¡ç†ï¼‰
    config = {
        "configurable": {
            "thread_id": f"file-analysis-{hash(sample_file_path) % 10000}",
        },
        "metadata": {
            "user": "test-user",
            "file_path": sample_file_path,
            "timestamp": str(Path(sample_file_path).stat().st_mtime) if Path(sample_file_path).exists() else "unknown"
        }
    }
    
    # æ‰§è¡Œå›¾
    try:
        print("\nå¼€å§‹æ‰§è¡Œåˆ†ææµç¨‹...\n")
        final_state = app.invoke(initial_state, config=config)
        
        # æ‰“å°æœ€ç»ˆç»“æœ
        print("\n" + "="*60)
        print("ğŸ“Š åˆ†æç»“æœ:")
        print("="*60)
        
        # è·å–æœ€åä¸€æ¡AIæ¶ˆæ¯
        for msg in reversed(final_state["messages"]):
            if isinstance(msg, AIMessage):
                print(msg.content)
                break
        
        print("\n" + "="*60)
        print("âœ… åˆ†æå®Œæˆï¼")
        
        if os.getenv("LANGCHAIN_API_KEY"):
            print("ğŸ” ä½ å¯ä»¥åœ¨ LangSmith (https://smith.langchain.com/) ä¸­æŸ¥çœ‹è¯¦ç»†çš„æ‰§è¡Œè¿½è¸ª")
        else:
            print("ğŸ’¡ æç¤º: è®¾ç½® LANGCHAIN_API_KEY ç¯å¢ƒå˜é‡ä»¥å¯ç”¨ LangSmith è¿½è¸ª")
        
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        raise

if __name__ == "__main__":
    main()

# --- ç”¨äºLangGraph DevæœåŠ¡å™¨ ---
def get_app():
    """
    è¿”å›åº”ç”¨å®ä¾‹ï¼Œç”¨äºlanggraph devæœåŠ¡å™¨
    
    ä½¿ç”¨æ–¹æ³•:
    1. åœ¨ç»ˆç«¯è¿è¡Œ: langgraph dev
    2. æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://localhost:8123
    3. åœ¨LangGraph Studioä¸­æµ‹è¯•æ™ºèƒ½ä½“
    """
    return create_file_analysis_graph()

# å¯¼å‡ºå›¾å®šä¹‰ï¼ˆå¯é€‰ï¼Œç”¨äºå¯è§†åŒ–ï¼‰
graph = get_app()